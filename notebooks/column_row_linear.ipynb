{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc174ab-9ce8-45c9-a582-43480767dc75",
   "metadata": {},
   "source": [
    "# Tensor Parallel row-wise vs column-wise\n",
    "\n",
    "There are two ways a linear layer can be split up across GPUs: row-wise or column-wise\n",
    "\n",
    "## Question: \n",
    "\n",
    "If we want to do a linear transformation on input `X` by matrix multiplying it (`@`) with parameters `W1`, then apply a non-linear activation function `gelu()`,then one more linear transformation by matrix multiplying with `W2` to get \n",
    "\n",
    "$$ y = gelu(X @ W1) @ W2 $$\n",
    "\n",
    "\n",
    "Which of these methods of tensor parallelizing `X @ W1` and `X @ W2` will be fastest in terms of minimizing data tansfer across GPU while keeping the final result `y` the same as had we not used parallelism and kept the computation on one CPU or GPU.\n",
    "\n",
    "- a) column-wise-parallel-matmul -> all-gather -> gelu -> column-wise-parallel-matmul -> all-gather\n",
    "\n",
    "- b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d4c750-2a94-4e68-b903-b07a641e71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; torch.manual_seed(42)\n",
    "from torch.nn.functional import gelu # f() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0cb7e95-40ce-4de7-9a6f-e9882205d8b9",
   "metadata": {},
   "source": [
    "<img src=\"pics/matmul.png\" height=200 width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f2110b-3b2b-48f4-8266-6741cbc84924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5324, 0.2612, 0.0106, 0.7086],\n",
       "        [1.1399, 2.8075, 1.8650, 1.5034]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(2, 4, device=\"cpu\", dtype=torch.float32)\n",
    "W = torch.randn(4, 4, device=\"cpu\", dtype=torch.float32)\n",
    "\n",
    "y = gelu(X @ W)\n",
    "\n",
    "print(\"Baseline\")\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71248eb4-81fa-48ce-90f9-64dc53a2a369",
   "metadata": {},
   "source": [
    "<img src=\"pics/column_wise_parallel.png\" height=300 width=600>\n",
    "\n",
    "W is split horizontally (dim=1) and the outputs of the separate matmuls is concatenated (all_gather) along that same dimension horizontally (dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c981ec0-e821-4416-8e5a-e3dd49561b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column linear match\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5324, 0.2612, 0.0106, 0.7086],\n",
       "        [1.1399, 2.8075, 1.8650, 1.5034]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column linear\n",
    "\n",
    "W_0, W_1 = W.chunk(2, dim=1) # W is split horizontally (dim=1)\n",
    "\n",
    "y_col_1 = torch.cat([gelu(X @ W_0), gelu(X @ W_1)], dim=1) # concatenate after the nonlinearity\n",
    "\n",
    "y_col_2 = gelu(torch.cat([X @ W_0, X @ W_1], dim=1)) # concatenate before the nonlinearity\n",
    "\n",
    "try:\n",
    "    torch.testing.assert_close(y_col_1, y_col_2, rtol=1e-5, atol=1e-5)\n",
    "    col_match = True\n",
    "    print(\"Column linear match\")\n",
    "except AssertionError:\n",
    "    col_match = False\n",
    "    print(\"Column linear mismatch\")\n",
    "\n",
    "y_col_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e8648-2a4e-4ad1-ab2d-0e38d46e9985",
   "metadata": {},
   "source": [
    "<img src=\"pics/row_wise_parallel.png\" height=350 width=700>\n",
    "\n",
    "X is split horizontally (dim=1) and W is split vertically (dim=0). There is no concatenation step but rather a elementwise addition (all_reduce) step at the end. \n",
    "\n",
    "Unlike Colum-wise linear you cannot apply the non-linearity before the synchronization (all-gather, all-reduce) steps, because the activation function is non-linear, `f(a) + f(b) != f(a+b)` but `f(concat(a, b)) = concat(f(a), f(b))`\n",
    "\n",
    "Note however that after the initial row-wise parallel split, before the matmul, the distribution of input tensors (X_0, X_1) across GPUs in row-wise parallel is the same as the distribution of tensors (X @ W_0, X @ W_1) across GPUs in column-wise parallel after the matmul step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9162864-7d7f-4ed9-95dc-ca079c86267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row linear mismatch\n",
      "tensor([[0.4549, 0.2409, 0.0150, 0.5894],\n",
      "        [2.8925, 2.8190, 1.6791, 2.2097]]) \n",
      "\n",
      " tensor([[0.5324, 0.2612, 0.0106, 0.7086],\n",
      "        [1.1399, 2.8075, 1.8650, 1.5034]])\n"
     ]
    }
   ],
   "source": [
    "# Row linear\n",
    "\n",
    "X_0, X_1 = X.chunk(2, dim=1) # X is split horizontally (dim=1)\n",
    "W_0, W_1 = W.chunk(2, dim=0) # W is split vertically (dim=0)\n",
    "\n",
    "y_row_1 = gelu(X_0 @ W_0) + gelu(X_1 @ W_1) # element-wise addtion after the nonlinearity\n",
    "y_row_2 = gelu(X_0 @ W_0 + X_1 @ W_1) # element-wise addtion before the nonlinearity\n",
    "\n",
    "try:\n",
    "    torch.testing.assert_close(y_row_1, y_row_2, rtol=1e-5, atol=1e-5)\n",
    "    col_match = True\n",
    "    print(\"Row linear match\")\n",
    "except AssertionError:\n",
    "    col_match = False\n",
    "    print(\"Row linear mismatch\")\n",
    "\n",
    "print(y_row_1, \"\\n\\n\", y_row_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d3480a-5389-4368-a20b-7ee70d6e5de7",
   "metadata": {},
   "source": [
    "<img src=\"pics/column_row_parallel.png\" height=350 width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f0f5cf-5ceb-4921-be80-84731852c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1601, -0.0207,  0.0361, -0.1454],\n",
       "        [ 0.5498,  0.3071, -0.1691,  1.1577]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(2, 4, device=\"cpu\", dtype=torch.float32)\n",
    "W1 = torch.randn(4, 4, device=\"cpu\", dtype=torch.float32)\n",
    "W2 = torch.randn(4, 4, device=\"cpu\", dtype=torch.float32)\n",
    "\n",
    "y = gelu(X @ W1) @ W2\n",
    "\n",
    "print(\"Baseline\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39648302-b843-4a16-b0ac-9b4089f9298f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1601, -0.0207,  0.0361, -0.1454],\n",
       "        [ 0.5498,  0.3071, -0.1691,  1.1577]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1_0, W1_1 = W1.chunk(2, dim=1) # W is split horizontally (dim=1)\n",
    "W2_0, W2_1 = W2.chunk(2, dim=0) # W is split vertically (dim=0)\n",
    "\n",
    "X2_0 = gelu(X @ W1_0)\n",
    "X2_1 = gelu(X @ W1_1)\n",
    "\n",
    "y_col_row = X2_0 @ W2_0 + X2_1 @ W2_1\n",
    "y_col_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583fddc-ce32-49e4-8e0e-111cdc247738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
